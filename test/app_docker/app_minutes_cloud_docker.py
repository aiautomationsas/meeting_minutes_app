import os
from langgraph_sdk import get_client
from typing import Optional, Tuple
import asyncio
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
import json

load_dotenv()

async def create_new_thread(client) -> Optional[str]:
    """Create a new thread for each minutes processing."""
    try:
        thread_response = await client.threads.create()
        thread_id = thread_response["thread_id"]
        print(f"\nğŸ”„ Nuevo thread creado: {thread_id[:8]}...")
        return thread_id
    except Exception as e:
        print(f"âŒ Error creating new thread: {str(e)}")
        return None

async def initialize_assistant() -> Tuple[Optional[str], Optional[object]]:
    try:
        client = get_client(url="http://localhost:8123/")
        
        assistant_id = os.getenv("ASSISTANT_ID_MINUTES")
        if not assistant_id:
            print("Error: ASSISTANT_ID_MINUTES environment variable not found")
            return None, None
        
        return assistant_id, client
    except Exception as e:
        print(f"Error initializing assistant: {str(e)}")
        return None, None

async def process_stream_event(event) -> None:
    """Process streaming events, focusing on the last AI response."""
    try:
        if hasattr(event, 'data') and isinstance(event.data, dict):
            messages = event.data.get('messages', [])
            if messages:
                # Obtener el Ãºltimo mensaje de tipo 'ai'
                ai_messages = [msg for msg in messages if msg.get('type') == 'ai']
                if ai_messages:
                    last_ai_message = ai_messages[-1]
                    content = last_ai_message.get('content', '')
                    try:
                        # Intentar parsear como JSON para mejor formato
                        acta = json.loads(content)
                        print("\nğŸ“„ Ãšltima versiÃ³n del acta:")
                        print(json.dumps(acta, ensure_ascii=False, indent=2))
                    except json.JSONDecodeError:
                        # Si no es JSON, mostrar como texto plano
                        print("\nğŸ“„ Ãšltima respuesta:")
                        print(content)
    except Exception as e:
        print(f"\nâŒ Error processing event: {str(e)}")

async def process_minutes(client, assistant_id: str, minutes_text: str):
    """Process minutes text with a new thread and handle streaming."""
    thread_id = await create_new_thread(client)
    if not thread_id:
        print("âŒ Error: Could not create new thread")
        return

    print("\nğŸ” Procesando acta...")
    initial_state = {
        "messages": [
            HumanMessage(content=minutes_text)
        ]
    }
    
    try:
        # Procesamiento inicial
        print("â³ Generando respuesta inicial...")
        stream = client.runs.stream(
            assistant_id=assistant_id,
            thread_id=thread_id,
            input=initial_state,
            stream_mode="values",
            interrupt_before=["human_critique"]
        )
        
        async for event in stream:
            await process_stream_event(event)
        
        # Ciclo de crÃ­ticas del usuario
        while True:
            print("\nğŸ“ Por favor, ingrese sus comentarios (o 'Aprobado' si estÃ¡ conforme):")
            user_comments = input().strip()
            
            # Actualizar el estado con los comentarios del usuario
            update_state = {
                "messages": [
                    HumanMessage(content=user_comments)
                ]
            }
            
            print("\nğŸ”„ Procesando comentarios...")
            await client.threads.update_state(
                thread_id, 
                update_state,
                as_node="human_critique"
            )
            
            # Si es aprobado, hacer una Ãºltima ejecuciÃ³n sin interrupciÃ³n
            if user_comments.lower() == "aprobado" or user_comments == "":
                print("\nâœ… Finalizando proceso de aprobaciÃ³n...")
                async for chunk in client.runs.stream(
                    assistant_id=assistant_id,
                    thread_id=thread_id,
                    input=None,
                    stream_mode="values"  # Sin interrupt_before para la aprobaciÃ³n final
                ):
                    await process_stream_event(chunk)
                print("\nâœ… Acta aprobada y proceso completado")
                break
            else:
                # Continuar el procesamiento despuÃ©s del update para crÃ­ticas
                print("\nâ³ Procesando actualizaciÃ³n...")
                async for chunk in client.runs.stream(
                    assistant_id=assistant_id,
                    thread_id=thread_id,
                    input=None,
                    stream_mode="values",
                    #interrupt_before=["human_critique"]  # Solo para crÃ­ticas
                ):
                    await process_stream_event(chunk)
            
    except Exception as e:
        print(f"\nâŒ Error durante el streaming: {str(e)}")
        print(f"Detalles del error: {str(e)}")
    finally:
        if 'stream' in locals():
            await stream.aclose()
        print("\nâœ… Procesamiento completado")

async def main():
    print("\nğŸš€ Iniciando sistema de actas...")
    assistant_id, client = await initialize_assistant()
    if not all([assistant_id, client]):
        print("âŒ Error: Failed to initialize. Exiting.")
        return

    print("\nğŸ‘‹ Bienvenido al sistema de actas de reuniÃ³n")
    print("â„¹ï¸  Puede escribir 'salir' en cualquier momento para terminar")
    while True:
        print("\nğŸ“ Por favor, ingrese el acta de la reuniÃ³n:")
        minutes_text = input().strip()
        
        if minutes_text.lower() == 'salir':
            print("\nğŸ‘‹ Gracias por usar el sistema de actas.")
            break
            
        if minutes_text:
            await process_minutes(client, assistant_id, minutes_text)
        else:
            print("âš ï¸  Por favor, ingrese un texto vÃ¡lido.")

if __name__ == "__main__":
    asyncio.run(main())