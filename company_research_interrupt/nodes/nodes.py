from typing import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, ToolMessage, AIMessage
from langgraph.types import Command
import json

from company_research_interrupt.state.types import ResearchState
from company_research_interrupt.nodes.tools import tools, tools_by_name

# Initialize model
model = ChatOpenAI(model="gpt-4-turbo-preview", temperature=0).bind_tools(tools)

async def tool_node(state: ResearchState):
    """Process tool calls and store results."""
    docs = state.get('documents', {})
    tool_messages = []
    
    last_message = state["messages"][-1]
    if not hasattr(last_message, "tool_calls"):
        return {
            "messages": [],
            "documents": docs,
            "awaiting_review": False,
            "research_complete": False
        }
    
    for tool_call in last_message.tool_calls:
        try:
            tool = tools_by_name[tool_call["name"]]
            results = await tool.ainvoke(tool_call["args"]["query"])
            
            new_docs = json.loads(results)
            docs_str = ""
            
            for doc in new_docs:
                if doc['url'] not in docs:
                    docs[doc['url']] = doc
                    title = doc.get('title', 'Sin t칤tulo')
                    content = doc.get('content', doc.get('snippet', 'Sin contenido'))
                    docs_str += f"\nFuente: {doc['url']}\nT칤tulo: {title}\nContenido: {content}\n"
            
            tool_messages.append(
                ToolMessage(
                    content=docs_str or "No se encontraron resultados relevantes.",
                    tool_call_id=tool_call["id"]
                )
            )
        except Exception as e:
            print(f"Error processing tool call: {str(e)}")
            tool_messages.append(
                ToolMessage(
                    content="Error al procesar la b칰squeda.",
                    tool_call_id=tool_call["id"]
                )
            )
    
    return {
        "messages": tool_messages,
        "documents": docs,
        "research_count": state.get('research_count', 0) + 1,
        "awaiting_review": True,
        "research_complete": False
    }

def human_review_sources(state: ResearchState) -> Command[Literal["generate_report"]]:
    """Allow human to review and filter sources before continuing."""
    docs = state.get('documents', {})
    
    print("\n游 Revisi칩n de fuentes encontradas:")
    for url, doc in docs.items():
        print(f"\n游댕 {url}")
        print(f"游늼 {doc.get('title', 'Sin t칤tulo')}")
    
    while True:
        print("\n쮻esea continuar con estas fuentes? (s/n):")
        response = input().strip().lower()
        
        if response == 's':
            return Command(
                goto="generate_report",
                update={
                    "awaiting_review": False,
                    "research_complete": True,
                    "messages": [SystemMessage(content="Generate report using only the approved sources.")],
                    "documents": docs
                }
            )
        elif response == 'n':
            print("\nSeleccione las URLs a mantener (separadas por coma):")
            selected_urls = [url.strip() for url in input().strip().split(',')]
            filtered_docs = {
                url: doc 
                for url, doc in docs.items() 
                if url in selected_urls
            }
            
            return Command(
                goto="generate_report",
                update={
                    "documents": filtered_docs,
                    "awaiting_review": False,
                    "research_complete": True,
                    "messages": [SystemMessage(content="Generate report using only the approved sources.")]
                }
            )
        else:
            print("Por favor, responda 's' o 'n'")

def call_model(state: ResearchState):
    """Generate research queries."""
    prompt = """You are an expert researcher tasked with preparing a detailed company report.
    Use the tavily_search tool to find relevant information.
    Make ONE search at a time and wait for the results before making additional searches.
    Focus on recent news, financial data, and significant developments."""
    
    messages = state.get('messages', []) + [SystemMessage(content=prompt)]
    response = model.invoke(messages)
    return {"messages": [response]}

def write_report(state: ResearchState):
    """Generate final report."""
    docs = state.get('documents', {})
    
    print("\n游닄 Generando informe con las siguientes fuentes:")
    for url, doc in docs.items():
        print(f"\n游댕 {url}")
        print(f"游늼 {doc.get('title', 'Sin t칤tulo')}")
    
    sources_text = ""
    urls_text = "\nFuentes consultadas:\n"
    for url, doc in docs.items():
        sources_text += f"\nURL: {url}\n"
        sources_text += f"T칤tulo: {doc.get('title', 'Sin t칤tulo')}\n"
        sources_text += f"Contenido: {doc.get('content', doc.get('snippet', 'Sin contenido'))}\n"
        sources_text += "-" * 50 + "\n"
        urls_text += f"- {url}\n"
    
    prompt = f"""Por favor, genera un informe detallado de la empresa utilizando EXCLUSIVAMENTE la informaci칩n de las siguientes fuentes aprobadas:

{sources_text}

IMPORTANTE:
1. Usa 칔NICAMENTE la informaci칩n de las fuentes proporcionadas arriba
2. NO agregues informaci칩n externa o de otras fuentes
3. Si alg칰n dato no est치 en las fuentes proporcionadas, NO lo incluyas
4. Enf칩cate en:
   - Datos financieros recientes
   - Posici칩n en el mercado
   - Desarrollos significativos
5. Estructura el informe de manera clara y profesional
6. Responde en espa침ol
7. INCLUYE AL FINAL DEL INFORME la siguiente secci칩n de fuentes:

{urls_text}"""
    
    messages = [SystemMessage(content=prompt)]
    response = model.invoke(messages)
    
    return {
        "messages": [AIMessage(content=response.content)],
        "report": response.content,
        "research_complete": True,
        "awaiting_review": False
    }